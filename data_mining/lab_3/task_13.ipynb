{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "PATH = \"lab/data/\"\n",
    "df_ari_raw = pd.read_csv(f'{PATH}Credit.csv')\n",
    "df_ari_raw = df_ari_raw.drop(\"Unnamed: 0\", axis=1)\n",
    "df_ari = pd.get_dummies(df_ari_raw)\n",
    "df_ari_y = df_ari.apply(lambda row: 1 if row['Income'] > 50 else 0, axis=1)  # making new column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## a) K-Nearest Neighbors Classifier & Decision Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def perform_classifier_routine(classifier_class, X_train, y_train, X_test, y_test, verbose, **kwargs):\n",
    "    classifier = classifier_class(**kwargs)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    if verbose is True:\n",
    "        print(f\"{kwargs=}, {score=}\")\n",
    "    return classifier, score\n",
    "\n",
    "\n",
    "def get_best_classifier(X_train, y_train, X_test, y_test, verbose):\n",
    "    best_score = -1\n",
    "    for neighbours in range(1, 10):\n",
    "        knn, new_score = perform_classifier_routine(KNeighborsClassifier, X_train, y_train, X_test, y_test, verbose,\n",
    "                                                    n_neighbors=neighbours)\n",
    "        if new_score > best_score:\n",
    "            best_neighbours = neighbours\n",
    "            best_score = new_score\n",
    "            best_knn = knn\n",
    "    print(f\"{best_neighbours=} with {best_score=}\")\n",
    "\n",
    "    best_score = -1\n",
    "    for depth in range(1, 10):\n",
    "        dt, new_score = perform_classifier_routine(DecisionTreeClassifier, X_train, y_train, X_test, y_test, verbose,\n",
    "                                                   max_depth=depth)\n",
    "        if new_score > best_score:\n",
    "            best_depth = depth\n",
    "            best_score = new_score\n",
    "            best_dt = dt\n",
    "    print(f\"{best_depth=} with {best_score=}\")\n",
    "\n",
    "    best_score = -1\n",
    "    for estimators in [10, 25, 50, 100, 200]:\n",
    "        rf, new_score = perform_classifier_routine(RandomForestClassifier, X_train, y_train, X_test, y_test, verbose,\n",
    "                                                   n_estimators=estimators)\n",
    "        if new_score > best_score:\n",
    "            best_estimators = estimators\n",
    "            best_score = new_score\n",
    "            best_rf = rf\n",
    "    print(f\"{best_estimators=} with {best_score=}\")\n",
    "\n",
    "\n",
    "def find_best_classifier(data_frame, data_frame_y, verbose=True):\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(data_frame)):\n",
    "        print(f\"{i}-th fold:\")\n",
    "        X_train, X_test = data_frame.iloc[train_index], data_frame.iloc[test_index]\n",
    "        y_train, y_test = data_frame_y.iloc[train_index], data_frame_y.iloc[test_index]\n",
    "\n",
    "        get_best_classifier(X_train, y_train, X_test, y_test, verbose)\n",
    "        print()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th fold:\n",
      "    Income  Limit  Rating  Cards  Age  Education  Balance  Gender_ Male  \\\n",
      "0   14.891   3606     283      2   34         11      333             1   \n",
      "1  106.025   6645     483      3   82         15      903             0   \n",
      "3  148.924   9504     681      3   36         11      964             0   \n",
      "4   55.882   4897     357      2   68         16      331             1   \n",
      "5   80.180   8047     569      4   77         10     1151             1   \n",
      "\n",
      "   Gender_Female  Student_No  Student_Yes  Married_No  Married_Yes  \\\n",
      "0              0           1            0           0            1   \n",
      "1              1           0            1           0            1   \n",
      "3              1           1            0           1            0   \n",
      "4              0           1            0           0            1   \n",
      "5              0           1            0           1            0   \n",
      "\n",
      "   Ethnicity_African American  Ethnicity_Asian  Ethnicity_Caucasian  \n",
      "0                           0                0                    1  \n",
      "1                           0                1                    0  \n",
      "3                           0                1                    0  \n",
      "4                           0                0                    1  \n",
      "5                           0                0                    1  \n",
      "best_neighbours=1 with best_score=0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.config/JetBrains/DataSpell2022.2/projects/workspace/venv/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Age\n",
      "- Balance\n",
      "- Cards\n",
      "- Education\n",
      "- Ethnicity_African American\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but KNeighborsClassifier is expecting 16 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mfind_best_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_ari\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_ari_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[51], line 60\u001B[0m, in \u001B[0;36mfind_best_classifier\u001B[0;34m(data_frame, data_frame_y, verbose)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28mprint\u001B[39m(X_train\u001B[38;5;241m.\u001B[39mhead())\n\u001B[1;32m     58\u001B[0m y_train, y_test \u001B[38;5;241m=\u001B[39m data_frame_y\u001B[38;5;241m.\u001B[39miloc[train_index], data_frame_y\u001B[38;5;241m.\u001B[39miloc[test_index]\n\u001B[0;32m---> 60\u001B[0m \u001B[43mget_best_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28mprint\u001B[39m()\n",
      "Cell \u001B[0;32mIn[51], line 30\u001B[0m, in \u001B[0;36mget_best_classifier\u001B[0;34m(X_train, y_train, X_test, y_test, verbose)\u001B[0m\n\u001B[1;32m     28\u001B[0m         best_knn \u001B[38;5;241m=\u001B[39m knn\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_neighbours\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_score\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 30\u001B[0m \u001B[43mplot_decision_boundaries\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_knn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mIncome\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRating\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m best_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m depth \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m10\u001B[39m):\n",
      "Cell \u001B[0;32mIn[51], line 13\u001B[0m, in \u001B[0;36mplot_decision_boundaries\u001B[0;34m(clf, X)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_decision_boundaries\u001B[39m(clf, X):\n\u001B[1;32m     11\u001B[0m     cm \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mcm\u001B[38;5;241m.\u001B[39mRdBu\n\u001B[0;32m---> 13\u001B[0m     disp \u001B[38;5;241m=\u001B[39m \u001B[43mDecisionBoundaryDisplay\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_estimator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mylabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m     disp\u001B[38;5;241m.\u001B[39max_\u001B[38;5;241m.\u001B[39mscatter(X[:, \u001B[38;5;241m0\u001B[39m], X[:, \u001B[38;5;241m1\u001B[39m], edgecolor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     17\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~/.config/JetBrains/DataSpell2022.2/projects/workspace/venv/lib/python3.9/site-packages/sklearn/inspection/_plot/decision_boundary.py:306\u001B[0m, in \u001B[0;36mDecisionBoundaryDisplay.from_estimator\u001B[0;34m(cls, estimator, X, grid_resolution, eps, plot_method, response_method, xlabel, ylabel, ax, **kwargs)\u001B[0m\n\u001B[1;32m    303\u001B[0m     X_grid \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mc_[xx0\u001B[38;5;241m.\u001B[39mravel(), xx1\u001B[38;5;241m.\u001B[39mravel()]\n\u001B[1;32m    305\u001B[0m pred_func \u001B[38;5;241m=\u001B[39m _check_boundary_response_method(estimator, response_method)\n\u001B[0;32m--> 306\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mpred_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_grid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;66;03m# convert classes predictions into integers\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pred_func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(estimator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclasses_\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/.config/JetBrains/DataSpell2022.2/projects/workspace/venv/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:275\u001B[0m, in \u001B[0;36mKNeighborsClassifier.predict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;124;03m\"\"\"Return probability estimates for the test data X.\u001B[39;00m\n\u001B[1;32m    258\u001B[0m \n\u001B[1;32m    259\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;124;03m    by lexicographic order.\u001B[39;00m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;66;03m# In that case, we do not need the distances to perform\u001B[39;00m\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;66;03m# the weighting so we do not compute them.\u001B[39;00m\n\u001B[0;32m--> 275\u001B[0m     neigh_ind \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkneighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    276\u001B[0m     neigh_dist \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.config/JetBrains/DataSpell2022.2/projects/workspace/venv/lib/python3.9/site-packages/sklearn/neighbors/_base.py:745\u001B[0m, in \u001B[0;36mKNeighborsMixin.kneighbors\u001B[0;34m(self, X, n_neighbors, return_distance)\u001B[0m\n\u001B[1;32m    743\u001B[0m         X \u001B[38;5;241m=\u001B[39m _check_precomputed(X)\n\u001B[1;32m    744\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 745\u001B[0m         X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    747\u001B[0m n_samples_fit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_samples_fit_\n\u001B[1;32m    748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_neighbors \u001B[38;5;241m>\u001B[39m n_samples_fit:\n",
      "File \u001B[0;32m~/.config/JetBrains/DataSpell2022.2/projects/workspace/venv/lib/python3.9/site-packages/sklearn/base.py:600\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 600\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    602\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/.config/JetBrains/DataSpell2022.2/projects/workspace/venv/lib/python3.9/site-packages/sklearn/base.py:400\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[0;32m--> 400\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    401\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    402\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    403\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: X has 2 features, but KNeighborsClassifier is expecting 16 features as input."
     ]
    }
   ],
   "source": [
    "find_best_classifier(df_ari, df_ari_y, verbose=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b) K-Nearest Neighbors Classifier & Decision Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test score:  0.325\n"
     ]
    }
   ],
   "source": [
    "PATH = \"lab/data/\"\n",
    "df_cards_raw = pd.read_csv(f'{PATH}Credit.csv')\n",
    "df_cards = df_cards_raw.drop(\"Unnamed: 0\", axis=1)\n",
    "df_cards = pd.get_dummies(df_cards)  # one hot encoding for category data\n",
    "df_cards_y = df_cards.pop('Cards')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th fold:\n",
      "best_neighbours=2\n",
      "best_depth=1\n",
      "\n",
      "1-th fold:\n",
      "best_neighbours=1\n",
      "best_depth=3\n",
      "\n",
      "2-th fold:\n",
      "best_neighbours=7\n",
      "best_depth=7\n",
      "\n",
      "3-th fold:\n",
      "best_neighbours=8\n",
      "best_depth=7\n",
      "\n",
      "4-th fold:\n",
      "best_neighbours=3\n",
      "best_depth=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_best_classifier(df_cards, df_cards_y, verbose=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
